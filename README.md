# ğŸ“° News Scraper RSS

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Pandas](https://img.shields.io/badge/Pandas-2.0+-green.svg)](https://pandas.pydata.org/)
[![BeautifulSoup](https://img.shields.io/badge/BeautifulSoup-4.x-orange.svg)](https://www.crummy.com/software/BeautifulSoup/)

## ğŸ“ Sobre o Projeto
Este Ã© um script de automaÃ§Ã£o desenvolvido para extrair notÃ­cias de feeds RSS/XML de portais de tecnologia (configurado por padrÃ£o para o TechCrunch). O objetivo Ã© coletar tÃ­tulos, links e datas de publicaÃ§Ã£o de forma estruturada para permitir anÃ¡lises de dados e monitoramento de tendÃªncias.

Este foi o meu primeiro projeto de Web Scraping, focado em entender o ciclo de vida de uma requisiÃ§Ã£o HTTP atÃ© a persistÃªncia dos dados em formato tabular.

## ğŸ‘¤ Autor
* **Daniel Andrade** - [Seu Perfil no GitHub](https://github.com/seu-usuario)

## ğŸš€ Funcionalidades
* Coleta automatizada via protocolo HTTP.
* Parsing de arquivos XML/RSS usando **BeautifulSoup**.
* EstruturaÃ§Ã£o de dados com **Pandas**.
* ExportaÃ§Ã£o de relatÃ³rios em **CSV** com codificaÃ§Ã£o compatÃ­vel com Excel (`utf-8-sig`).

## ğŸ› ï¸ Tecnologias e DependÃªncias
Para rodar este projeto, vocÃª precisarÃ¡ das seguintes bibliotecas:

* **urllib**: Para requisiÃ§Ãµes ao servidor.
* **BeautifulSoup4**: Para extraÃ§Ã£o de dados das tags XML.
* **lxml**: Para processamento de alta performance do XML.
* **Pandas**: Para organizaÃ§Ã£o e exportaÃ§Ã£o dos dados.

## ğŸ“‹ Como usar
1. Clone o repositÃ³rio:
   ```bash
   git clone [https://github.com/seu-usuario/nome-do-repositorio.git](https://github.com/seu-usuario/nome-do-repositorio.git)
